\section{Experimental Methodology}
To see what is exactly happening under the hood, we conduct three experiments with AlexNet models built by aforementioned five deep learning frameworks. First, we measure the execution time of the AlexNet model for each framework to compare their characteristics. Unlike previous work, we measure layer-wise and GPU kernel-wise execution times as well as the execution time of a single batch. Second, we obtain performance characteristics of different convolution algorithms by profiling each GPU kernel implementation. Finally, we measure the training speed of each AlexNet implementation with multiple GPUs. Based on the experiment, we suggest possible optimization techniques to improve the scalability of CNNs. 

\begin{table}[htbp]
\centering
\caption{System Configuration}
\label{table_system}
\begin{scriptsize}
\begin{tabular}{|l|l|}
\hline\hline
CPU         & 2 x Intel Xeon E5 2650@2.0GHz \\\hline
GPU         & 4 x NVIDIA Titan X (GM200)    \\\hline
Main memory & 128GB DDR3                    \\\hline
GPU memory  & 4 x 12GB GDDR5                \\\hline
Operating system & CentOS 7.2.1511 (Linux 3.10.0-327)  \\\hline
\end{tabular}
\end{scriptsize}
\end{table}

Our experiments are performed with a system described in Table~\ref{table_system}. The versions of the deep learning frameworks and libraries used are described in Table~\ref{table_framework}. Torch is currently the only framework that officially supports cuDNN R5.1. In addition, the newest cuda-convnet3 is supported only by the ccn2.torch module in Torch. The comparison between the frameworks is done with cuDNN R5 and the comparison between different convolution algorithms is performed using cuDNN R5.1 with Torch7.

AlexNet models are trained for many iterations and profiled. After they are stabilized, an iteration for a single batch is selected for our analysis. Model parameters are carefully equalized across different frameworks to remove the effect from things other than the frameworks themselves.