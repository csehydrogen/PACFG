\section{Experiment setup}

\subsection{System setup}
We test the frameworks on the CentOS 7.2 server with 2 octa-core Xeon-E5 cpus and 4 GTX TITAN X(GM200) gpus.
We use Cuda 7.5 and cuDNN R5 which is officially supported by current versions of the frameworks.
Torch is currently the only framework that officially support cuDNN R5.1.
Also the newest Cuda-convnet3 is only supported by Torch's ccn2.torch module.
The comparisons between frameworks are done with same cuDNN R5 and the gpu kernel analysis is done using cuDNN R5.1 with Torch7.
The detailed environments are described on Table \ref{table_system} and \ref{table_software}.

\begin{table}[]
\centering
\caption{System Hardward Setup}
\label{table_system}
\begin{tabular}{ll}
Processor   & 2 x Intel Xeon E5 2650@2.0GHz \\
GPU         & 4 x NVIDIA Titan X(GM200)     \\
Main Memory & 128GB DDR3                    \\
GPU Memory  & 4 x 12GB GDDR5                \\
OS          & CentOS 7.2.1511               \\
Kernel      & Linux 3.10.0-327             
\end{tabular}
\end{table}

\begin{table}[]
\centering
\caption{Software Setup}
\label{table_software}
\begin{tabular}{ll}
CUDA 		& CUDA 7.5 \\
cuDNN		& 5.1.3(Torch) \/ 5.0.5(others)     \\
Cuda-convnet& ccn2.torch			\\
Theano		& 0.8.2                    \\
Torch		& 7                \\
cudnn.torch	& R5		\\
Tensorflow	& 0.10.0rc0     	\\
Caffe		& 1.0.0-rc3			\\
CNTK		& 1.7.2             
\end{tabular}
\end{table}

\subsection{AlexNet model}
AlexNet \cite{krizhevsky2012imagenet} is one of the earliest successful deep neural networks on image recognition task using ImageNet dataset.
AlexNet uses 5 convolution layers to extract features and 3 fully connected layers for classification.
Each layer has rectified linear unit(ReLU) layer for nonlinear activation.
AlexNet has been frequently used for benchmarking performance of machine learning libraries, because it utilizes most of the current DNN components such as convolution, max-pooling and dropout \cite{convnet-benchmarks}.
The original AlexNet model includes Local response normalization(LRN) layer, but we exclude it for benchmarking task since LRN is very rarely used in current convolutional neural networks.
The detailed layer structure of AlexNet model on this study is presented in Table \ref{alex_model}.


\begin{table*}[]
\centering
\caption{Alexnet model used on benchmarking}
\label{alex_model}
\begin{tabular}{llllllll}
Name    & Kernel(R) & Input Channels(C) & Ouput Channels(K) & Stride(K) & Sample width(W) & Params & Flop \\
Input   &           & 3                 &                   &           & 227 x 227       &        &      \\
Conv1   & 11 x 11   & 3                 & 96                & 4         & 55 x 55         & 35K    & 55G  \\
Pool    & 3 x 3     &                   &                   & 2         &                 &        &      \\
Conv2   & 5 x 5     & 96                & 256               & 1         & 27 x 27         & 614K   & 227G \\
Pool    & 3 x 3     &                   &                   & 2         &                 &        &      \\
Conv3   & 3 x 3     & 256               & 384               & 1         & 13 x 13         & 885K   & 65G  \\
Conv4   & 3 x 3     & 384               & 384               & 1         & 13 x 13         & 1.3M   & 98G  \\
Conv5   & 3 x 3     & 384               & 256               & 1         & 13 x 13         & 885K   & 65G  \\
Pool    & 3 x 3     &                   &                   & 2         &                 &        &      \\
FC6     &           & 256 x 6 x 6       & 4096              &           &                 & 37M    & 74M  \\
FC7     &           & 4096              & 4096              &           &                 & 16M    & 32M  \\
FC8     &           & 4096              & 1000              &           &                 & 4M     & 8M   \\
Softmax &           & 1000              & 1000              &           &                 &        &     
\end{tabular}
\end{table*}
