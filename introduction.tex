\section{Introduction}
Deep neural networks (DNNs) have been very successful in various machine learning tasks, such as visual recognition\cite{krizhevsky2012imagenet,vgg,RCNN}, speech recognition\cite{speech}, and machine translation\cite{machinetranslation}. Among others, the convolutional neural network (CNN) proposed by LeCun \textit{et al.}\cite{726791} is one of the earliest successful DNN models that were used to classify images. CNN models equipped with deep learning techniques (\textit{e.g.}, ReLU activation, dropout layers, data augmentation, etc.) outperform previous machine learning techniques in various visual recognition challenges, such as ILSVRC\cite{DBLP:journals/corr/RussakovskyDSKSMHKKBBF14} and PASCAL\cite{pascal}.

A larger and deeper CNN with more parameters usually results in a better accuracy. However, a larger CNN requires more processing power, and training it using a typical computer is impractical. Fortunately, computations in a CNN can easily be represented as tensor or matrix operations that can be efficiently parallelized. Thus, GPUs' massively parallel processing power makes CNNs to be trained efficiently, and most of popular deep learning frameworks support GPU acceleration by default\cite{DBLP:journals/corr/Al-RfouAAa16,jia2014caffe,tensorflow2015-whitepaper,torch,cntk}.

The most popular deep learning library for such frameworks is cuDNN\cite{cudnn} developed by NVIDIA, and most of the popular deep learning frameworks use it as the backend for GPUs. An approach to speed up CNNs is reducing the time complexity of convolution algorithms. Fast Fourier Transform (FFT) algorithms\cite{fftconv, fbfft} and Winograd's minimal filtering algorithm\cite{winograd} successfully reduce the algorithm complexity of the convolution computation in a CNN.
However, while the efficiency of a CNN on a single GPU has been improved a lot, its efficiency on multiple GPUs still shows poor scalability\cite{DBLP:journals/corr/YadanATR13}.

Users choose a deep learning framework to build their CNN models based on language interfaces, operating system support, performance, ease of use, etc. Ideally, the execution time of the same CNN model should be the same across all the frameworks when the input is the same. However, in reality, this is not true; a CNN model built with a framework delivers more than twice the performance compared to the same model built with a different framework\cite{DBLP:journals/corr/BahrampourRSS15,DBLP:journals/corr/ShiWXC16}. 

In this paper, we analyze the performance characteristics of CNN models built with different deep learning frameworks and libraries. For clarity, a \textit{framework} refers to a full collection of libraries to build DNN models and a \textit{library} refers to a GPU library such as cuDNN used in the framework. We choose five most popular deep learning frameworks, Caffe\cite{jia2014caffe}, CNTK\cite{cntk}, TensorFlow\cite{tensorflow2015-whitepaper}, Theano\cite{DBLP:journals/corr/Al-RfouAAa16}, and Torch\cite{torch}. The popularity criterion is the number of GitHub stars\cite{github}.

We choose a representative CNN model, AlexNet\cite{krizhevsky2012imagenet}, to compare the five frameworks and to obtain performance characteristics. Identically structured AlexNet models are built and trained using different frameworks. All the five frameworks use cuDNN as the GPU backend. Cuda-convnet\cite{cuda-convnet} is another GPU library used with those frameworks. In addition, we compare three different convolution algorithms of cuDNN with the direct convolution algorithm of Cuda-convnet.

Our comparative study provides useful insights to both end users and developers of a DNN framework. In the case of end users, their main interest is the accuracy and speed of the network in training and testing, not the optimization of the implementation. They sometimes do not know that their model built with the DNN framework is slower than those with other frameworks. Moreover, they do not know the reasons of slowdown either. On the other hand, the developers want to know where the bottlenecks occur to optimize their framework implementation. Both end users and developers want to improve the performance of DNN models built by their framework.

We identify which part of the GPU implementation of a framework is the performance bottleneck. This provides the developers with optimization possibilities. This will also help end users to choose a proper framework for their CNN models. 

The contributions of this work are as follows:
\begin{itemize}
\item We analyze differences in the performance characteristics of the five frameworks in a single GPU context. Unlike previous approaches, we measure layer-wise execution times as well as the processing time of an input batch. Based on the measurement, we identify performance limiting factors of each framework. 

\item We show the performance characteristics of different convolution algorithms. Based on the characteristics, we provide possible optimization techniques to implement efficient CNN models using the algorithm libraries.

\item We show the performance characteristics of the deep learning frameworks in multi-GPU contexts. We also provide possible techniques to improve the scalability of the frameworks in the multiple GPU context.
\end{itemize}

Based on the characteristics obtained, we increase the speed of training the AlexNet model up to 2X by just changing options provided by the framework compared to the same model built with default options. We do not modify the source code of the framework at all. Thus, the end users can easily adopt our techniques to their CNN model building processes.



